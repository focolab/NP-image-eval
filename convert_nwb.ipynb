{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open namespace and get extensions for multichannel volumetric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pynwb import load_namespaces, get_class\n",
    "from pynwb.file import MultiContainerInterface, NWBContainer\n",
    "\n",
    "# Set path of the namespace.yaml file to the expected install location\n",
    "MultiChannelVol_specpath = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'spec',\n",
    "    'ndx-multichannel-volume.namespace.yaml'\n",
    ")\n",
    "# Load the namespace\n",
    "load_namespaces(MultiChannelVol_specpath)\n",
    "\n",
    "# TODO: import your classes here or define your class using get_class to make\n",
    "# them accessible at the package level\n",
    "#MultiChannelVolume = get_class('MultiChannelVolume', 'ndx-multichannel-volume')\n",
    "#ImagingVolume = get_class('ImagingVolume', 'ndx-multichannel-volume')\n",
    "OpticalChannelReferences = get_class('OpticalChannelReferences', 'ndx-multichannel-volume')\n",
    "#VolumeSegmentation = get_class('VolumeSegmentation', 'ndx-multichannel-volume')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define VolumeSegmentation class and add necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "from pynwb import register_class\n",
    "from hdmf.utils import docval, get_docval, popargs\n",
    "from pynwb.ophys import ImageSeries \n",
    "from pynwb.core import NWBDataInterface\n",
    "from hdmf.common import DynamicTable\n",
    "from hdmf.utils import docval, popargs, get_docval, get_data_shape, popargs_to_dict\n",
    "from pynwb.file import Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_class('OpticalChannel', 'ndx-multichannel-volume')\n",
    "class OpticalChannel(NWBContainer):\n",
    "    \"\"\"An optical channel used to record from an imaging plane.\"\"\"\n",
    "\n",
    "    __nwbfields__ = ('description',\n",
    "                     'emission_lambda')\n",
    "\n",
    "    @docval({'name': 'name', 'type': str, 'doc': 'the name of this electrode'},  # required\n",
    "            {'name': 'description', 'type': str, 'doc': 'Any notes or comments about the channel.'},  # required\n",
    "            {'name': 'emission_lambda', 'type': float, 'doc': 'Emission wavelength for channel, in nm.'})  # required\n",
    "    def __init__(self, **kwargs):\n",
    "        description, emission_lambda = popargs(\"description\", \"emission_lambda\", kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "        self.description = description\n",
    "        self.emission_lambda = emission_lambda\n",
    "\n",
    "\n",
    "@register_class('ImagingVolume', 'ndx-multichannel-volume')\n",
    "class ImagingVolume(NWBDataInterface):\n",
    "    \"\"\"An imaging plane and its metadata.\"\"\"\n",
    "\n",
    "    __nwbfields__ = ({'name': 'optical_channels', 'child': True},\n",
    "                     'Order_optical_channels',\n",
    "                     'description',\n",
    "                     'device',\n",
    "                     'location',\n",
    "                     'conversion',\n",
    "                     'origin_coords',\n",
    "                     'origin_coords_units',\n",
    "                     'grid_spacing',\n",
    "                     'grid_spacing_units',\n",
    "                     'reference_frame',\n",
    "                     )\n",
    "\n",
    "    @docval(*get_docval(NWBDataInterface.__init__, 'name'),  # required\n",
    "            {'name': 'optical_channels', 'type': (list, OpticalChannel),  # required\n",
    "             'doc': 'One of possibly many groups storing channel-specific data.'},\n",
    "            {'name': 'Order_optical_channels', 'type':OpticalChannelReferences, 'doc':'Order of the optical channels in the data'},\n",
    "            {'name': 'description', 'type': str, 'doc': 'Description of this ImagingVolume.'},  # required\n",
    "            {'name': 'device', 'type': Device, 'doc': 'the device that was used to record'},  # required\n",
    "            {'name': 'location', 'type': str, 'doc': 'Location of image plane.'},  # required\n",
    "            {'name': 'reference_frame', 'type': str,\n",
    "             'doc': 'Describes position and reference frame of manifold based on position of first element '\n",
    "                    'in manifold.',\n",
    "             'default': None},\n",
    "            {'name': 'origin_coords', 'type': 'array_data',\n",
    "             'doc': 'Physical location of the first element of the imaging plane (0, 0) for 2-D data or (0, 0, 0) for '\n",
    "                    '3-D data. See also reference_frame for what the physical location is relative to (e.g., bregma).',\n",
    "             'default': None},\n",
    "            {'name': 'origin_coords_unit', 'type': str,\n",
    "             'doc': \"Measurement units for origin_coords. The default value is 'meters'.\",\n",
    "             'default': 'meters'},\n",
    "            {'name': 'grid_spacing', 'type': 'array_data',\n",
    "             'doc': \"Space between pixels in (x, y) or voxels in (x, y, z) directions, in the specified unit. Assumes \"\n",
    "                    \"imaging plane is a regular grid. See also reference_frame to interpret the grid.\",\n",
    "             'default': None},\n",
    "            {'name': 'grid_spacing_unit', 'type': str,\n",
    "             'doc': \"Measurement units for grid_spacing. The default value is 'meters'.\",\n",
    "             'default': 'meters'})\n",
    "    def __init__(self, **kwargs):\n",
    "        keys_to_set = ('optical_channels',\n",
    "                       'Order_optical_channels',\n",
    "                       'description',\n",
    "                       'device',\n",
    "                       'location',\n",
    "                       'reference_frame',\n",
    "                       'origin_coords',\n",
    "                       'origin_coords_unit',\n",
    "                       'grid_spacing',\n",
    "                       'grid_spacing_unit')\n",
    "        args_to_set = popargs_to_dict(keys_to_set, kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if not isinstance(args_to_set['optical_channels'], list):\n",
    "            args_to_set['optical_channels'] = [args_to_set['optical_channels']]\n",
    "\n",
    "        for key, val in args_to_set.items():\n",
    "            setattr(self, key, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_class('VolumeSegmentation', 'ndx-multichannel-volume')\n",
    "class VolumeSegmentation(DynamicTable):\n",
    "    \"\"\"\n",
    "    Stores pixels in an image that represent different regions of interest (ROIs)\n",
    "    or masks. All segmentation for a given imaging volume is stored together, with\n",
    "    storage for multiple imaging planes (masks) supported. Each ROI is stored in its\n",
    "    own subgroup, with the ROI group containing both a 3D mask and a list of pixels\n",
    "    that make up this mask. Segments can also be used for masking neuropil. If segmentation\n",
    "    is allowed to change with time, a new imaging plane (or module) is required and\n",
    "    ROI names should remain consistent between them.\n",
    "    \"\"\"\n",
    "\n",
    "    __fields__ = ('imaging_volume','name')\n",
    "\n",
    "    __columns__ = (\n",
    "        {'name': 'image_mask', 'description': 'Image masks for each ROI'},\n",
    "        {'name': 'voxel_mask', 'description': 'Voxel masks for each ROI', 'index': True}\n",
    "    )\n",
    "\n",
    "    @docval({'name': 'description', 'type': str,  # required\n",
    "             'doc': 'Description of image plane, recording wavelength, depth, etc.'},\n",
    "            {'name': 'imaging_volume', 'type': ImagingVolume,  # required\n",
    "             'doc': 'the ImagingVolume this ROI applies to'},\n",
    "            {'name': 'name', 'type': str, 'doc': 'name of VolumeSegmentation.', 'default': None},\n",
    "            *get_docval(DynamicTable.__init__, 'id', 'columns', 'colnames'))\n",
    "    def __init__(self, **kwargs):\n",
    "        imaging_volume = popargs('imaging_volume', kwargs)\n",
    "        if kwargs['name'] is None:\n",
    "            kwargs['name'] = imaging_volume.name\n",
    "        super().__init__(**kwargs)\n",
    "        self.imaging_volume = imaging_volume\n",
    "\n",
    "    @docval({'name': 'voxel_mask', 'type': 'array_data', 'default': None,\n",
    "             'doc': 'voxel mask for 3D ROIs: [(x1, y1, z1, weight1, ID), (x2, y2, z2, weight2, ID), ...]',\n",
    "             'shape': (None, 5)},\n",
    "            {'name': 'image_mask', 'type': 'array_data', 'default': None,\n",
    "             'doc': 'image with the same size of image where positive values mark this ROI',\n",
    "             'shape': [[None]*3]},\n",
    "            {'name': 'id', 'type': int, 'doc': 'the ID for the ROI', 'default': None},\n",
    "            allow_extra=True)\n",
    "    def add_roi(self, **kwargs):\n",
    "        \"\"\"Add a Region Of Interest (ROI) data to this\"\"\"\n",
    "        voxel_mask, image_mask = popargs('voxel_mask', 'image_mask', kwargs)\n",
    "        if image_mask is None and voxel_mask is None:\n",
    "            raise ValueError(\"Must provide 'image_mask' and/or 'voxel_mask'\")\n",
    "        rkwargs = dict(kwargs)\n",
    "        if image_mask is not None:\n",
    "            rkwargs['image_mask'] = image_mask\n",
    "        if voxel_mask is not None:\n",
    "            rkwargs['voxel_mask'] = voxel_mask\n",
    "        return super().add_row(**rkwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def voxel_to_image(voxel_mask):\n",
    "        \"\"\"Converts a #D pixel_mask of a ROI into an image_mask.\"\"\"\n",
    "        image_matrix = np.zeros(np.shape(voxel_mask))\n",
    "        npmask = np.asarray(voxel_mask)\n",
    "        x_coords = npmask[:, 0].astype(np.int32)\n",
    "        y_coords = npmask[:, 1].astype(np.int32)\n",
    "        z_coords = npmask[:, 2].astype(np.int32)\n",
    "        weights = npmask[:, -1]\n",
    "        image_matrix[y_coords, x_coords, z_coords] = weights\n",
    "        return image_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def image_to_pixel(image_mask):\n",
    "        \"\"\"Converts an image_mask of a ROI into a pixel_mask\"\"\"\n",
    "        voxel_mask = []\n",
    "        it = np.nditer(image_mask, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            weight = it[0][()]\n",
    "            if weight > 0:\n",
    "                x = it.multi_index[0]\n",
    "                y = it.multi_index[1]\n",
    "                z = it.multi_index[2]\n",
    "                voxel_mask.append([x, y, z, weight])\n",
    "            it.iternext()\n",
    "        return voxel_mask\n",
    "\n",
    "    @docval({'name': 'description', 'type': str, 'doc': 'a brief description of what the region is'},\n",
    "            {'name': 'region', 'type': (slice, list, tuple), 'doc': 'the indices of the table', 'default': slice(None)},\n",
    "            {'name': 'name', 'type': str, 'doc': 'the name of the ROITableRegion', 'default': 'rois'})\n",
    "    def create_roi_table_region(self, **kwargs):\n",
    "        return self.create_region(**kwargs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_class('MultiChannelVolume', 'ndx-multichannel-volume')\n",
    "class MultiChannelVolume(NWBDataInterface):\n",
    "    \"\"\"An imaging plane and its metadata.\"\"\"\n",
    "\n",
    "    __nwbfields__ = ('resolution',\n",
    "                     'description',\n",
    "                     'channels',\n",
    "                     'data',\n",
    "                     'imaging_volume'\n",
    "                     )\n",
    "\n",
    "    @docval(*get_docval(NWBDataInterface.__init__, 'name'),  # required\n",
    "            {'name': 'resolution', 'type': list, 'doc':'pixel resolution of the image', 'shape':[None]},\n",
    "            {'name': 'imaging_volume', 'type': ImagingVolume, 'doc': 'the Imaging Volume the data was generated from'},\n",
    "            {'name': 'description', 'type': str, 'doc':'description of image'},\n",
    "            {'name': 'channels', 'doc': 'description of what each channel in the image maps to', 'type': list, 'shape':[None]},\n",
    "            {'name': 'data', 'doc': 'Volumetric multichannel data', 'type': 'array_data', 'shape':[None]*4},\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        keys_to_set = ('resolution',\n",
    "                       'description',\n",
    "                       'channels',\n",
    "                       'data',\n",
    "                       'imaging_volume'\n",
    "                       )\n",
    "        args_to_set = popargs_to_dict(keys_to_set, kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        for key, val in args_to_set.items():\n",
    "            setattr(self, key, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NWB file for NeuroPAL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynwb import NWBFile, TimeSeries, NWBHDF5IO\n",
    "from pynwb.epoch import TimeIntervals\n",
    "from pynwb.file import Subject\n",
    "from pynwb.behavior import SpatialSeries, Position\n",
    "from pynwb.image import ImageSeries\n",
    "from pynwb.ophys import OnePhotonSeries, OpticalChannel, ImageSegmentation, Fluorescence, CorrectedImageStack, MotionCorrection, RoiResponseSeries\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NWB files should include\n",
    "General description of experimental conditions\n",
    "Time Series GCAMP data if available\n",
    "Multichannel NeuroPAL volume (extension)\n",
    "Point cloud of neuron centers (nx3)\n",
    "Associated Metadata\n",
    "\n",
    "'''\n",
    "\n",
    "session_start_time = datetime(2022,2,12, tzinfo=tz.gettz(\"US/Pacific\"))\n",
    "\n",
    "print(session_start_time)\n",
    "\n",
    "nwbfile = NWBFile(\n",
    "    session_description = \"Worm head\",\n",
    "    identifier = \"2022-02-12-w01-NP1\",\n",
    "    session_start_time = session_start_time,\n",
    "    lab = \"FOCO lab\",\n",
    "    institution = \"UCSF\",\n",
    "    related_publications = \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.subject = Subject(\n",
    "    subject_id= \"w01\",\n",
    "    age = \"YA\",\n",
    "    description = \"worm 1\",\n",
    "    species = \"C elegan\",\n",
    "    sex = \"XO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define Imaging plane which will include optical_channel and devic data\n",
    "'''\n",
    "\n",
    "device = nwbfile.create_device(\n",
    "    name=\"Microscope\",\n",
    "    description=\"One-photon microscope: Weill\",\n",
    "    manufacturer=\"Leica\"\n",
    ")\n",
    "\n",
    "channel_1 = OpticalChannel(\n",
    "    name=\"mNeptune 2.5\",\n",
    "    description=\"561-700-75m\",\n",
    "    emission_lambda=561.\n",
    ")\n",
    "\n",
    "channel_2 = OpticalChannel(\n",
    "    name=\"Tag RFP-T\",\n",
    "    description=\"561-605-70m\",\n",
    "    emission_lambda=561.\n",
    ")\n",
    "    \n",
    "channel_3 = OpticalChannel(\n",
    "    name=\"CyOFP1\",\n",
    "    description=\"488-605-70m\",\n",
    "    emission_lambda=488.\n",
    ")\n",
    "\n",
    "channel_4 = OpticalChannel(\n",
    "    name=\"GFP-GCaMP\",\n",
    "    description=\"488-525-50m\",\n",
    "    emission_lambda=488.\n",
    ")\n",
    "\n",
    "channel_5 = OpticalChannel(\n",
    "    name=\"mTagBFP2\",\n",
    "    description=\"405-460-50m\",\n",
    "    emission_lambda=405.\n",
    ")\n",
    "    \n",
    "channel_6 = OpticalChannel(\n",
    "    name=\"mNeptune 2.5 - high excite\",\n",
    "    description=\"639-700-75m\",\n",
    "    emission_lambda=639.\n",
    ")\n",
    "\n",
    "OpticalChannelRefs = OpticalChannelReferences(\n",
    "    name = 'OpticalChannelRefs',\n",
    "    data = [channel_1.description, channel_2.description, channel_3.description, channel_4.description, channel_5.description, channel_6.description]\n",
    ")\n",
    "\n",
    "imaging_vol = ImagingVolume(\n",
    "    name= \"imaging_volume\",\n",
    "    optical_channels=[channel_1, channel_2, channel_3, channel_4, channel_5, channel_6],\n",
    "    Order_optical_channels = OpticalChannelRefs,\n",
    "    description=\"NeuroPAL image of C elegan brain\",\n",
    "    device = device,\n",
    "    location = \"head\",\n",
    "    grid_spacing = [0.3208, 0.3208, 0.75],\n",
    "    grid_spacing_unit = 'micrometers',\n",
    "    origin_coords=[0,0,0],\n",
    "    origin_coords_unit = 'micrometers',\n",
    "    reference_frame = 'Head of C elegan with [0,0,0] in top left of the image and oriented as posterior on the left and ventral on top.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create plane_segmentation to define object that you add ROIs to\n",
    "Add voxel masks to display ROIs using arrays of triplets (x,y,weight)\n",
    "For our purposes just use weight of 1\n",
    "Can add time series fluorescence measurements for these ROIs if you want to \n",
    "''' \n",
    "\n",
    "vs = VolumeSegmentation(\n",
    "    name = 'VolumeSegmentation',\n",
    "    description = 'Neuron centers for multichannel volumetric image',\n",
    "    imaging_volume = imaging_vol\n",
    ")\n",
    "\n",
    "\n",
    "csv = pd.read_csv('data/NP_FOCO_cropped/2022-02-12-w01-NP1/blobs_og.csv') # read ROIs from blobs.csv\n",
    "\n",
    "voxel_mask = []\n",
    "\n",
    "for i, row in csv.iterrows():\n",
    "    x = row['X']\n",
    "    y = row['Y']\n",
    "    z = row['Z']\n",
    "    ID = row['ID']\n",
    "\n",
    "    voxel_mask.append((x,y,z,1,ID))\n",
    "\n",
    "vs.add_roi(voxel_mask=voxel_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding multichannel volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "\n",
    "data = np.transpose(skio.imread('data/NP_FOCO_cropped/2022-02-12-w01-NP1/neuropal_1_MMStack_Pos0.ome.tif'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image =  MultiChannelVolume(\n",
    "    name = '2022-02-12-w01-NP1',\n",
    "    imaging_volume = imaging_vol,\n",
    "    resolution = [0.3208, 0.3208, 0.75],\n",
    "    description = '2022-02-12-w01-NP1',\n",
    "    channels = ['red', 'white', 'green', 'GCAMP', 'blue', 'extra-red'],\n",
    "    data = data\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load everything into NWB file and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsprague/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'MultiChannelVolume/data': Value with data type uint16 is being converted to data type int16 as specified.\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n",
      "/Users/danielsprague/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/build/objectmapper.py:260: DtypeConversionWarning: Spec 'ImagingVolume/origin_coords': Value with data type int64 is being converted to data type float64 (min specification: float32).\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't implicitly convert non-string objects to strings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielsprague/FOCO_lab/NP_eval/convert_nwb.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielsprague/FOCO_lab/NP_eval/convert_nwb.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwriting\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielsprague/FOCO_lab/NP_eval/convert_nwb.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m io \u001b[39m=\u001b[39m NWBHDF5IO(\u001b[39m\"\u001b[39m\u001b[39mExample_NWB.nwb\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielsprague/FOCO_lab/NP_eval/convert_nwb.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m io\u001b[39m.\u001b[39;49mwrite(nwbfile)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielsprague/FOCO_lab/NP_eval/convert_nwb.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m io\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:360\u001b[0m, in \u001b[0;36mHDF5IO.write\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedOperation((\u001b[39m\"\u001b[39m\u001b[39mCannot write to file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m in mode \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m                                 \u001b[39m\"\u001b[39m\u001b[39mPlease use mode \u001b[39m\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m                                \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mode))\n\u001b[1;32m    359\u001b[0m cache_spec \u001b[39m=\u001b[39m popargs(\u001b[39m'\u001b[39m\u001b[39mcache_spec\u001b[39m\u001b[39m'\u001b[39m, kwargs)\n\u001b[0;32m--> 360\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mwrite(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m cache_spec:\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__cache_spec()\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/io.py:51\u001b[0m, in \u001b[0;36mHDMFIO.write\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m container \u001b[39m=\u001b[39m popargs(\u001b[39m'\u001b[39m\u001b[39mcontainer\u001b[39m\u001b[39m'\u001b[39m, kwargs)\n\u001b[1;32m     50\u001b[0m f_builder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__manager\u001b[39m.\u001b[39mbuild(container, source\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__source, root\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_builder(f_builder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:786\u001b[0m, in \u001b[0;36mHDF5IO.write_builder\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mWriting GroupBuilder \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to path \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with kwargs=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m                   \u001b[39m%\u001b[39m (f_builder\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource, kwargs))\n\u001b[1;32m    785\u001b[0m \u001b[39mfor\u001b[39;00m name, gbldr \u001b[39min\u001b[39;00m f_builder\u001b[39m.\u001b[39mgroups\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 786\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_group(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__file, gbldr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    787\u001b[0m \u001b[39mfor\u001b[39;00m name, dbldr \u001b[39min\u001b[39;00m f_builder\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__file, dbldr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:968\u001b[0m, in \u001b[0;36mHDF5IO.write_group\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[39mif\u001b[39;00m subgroups:\n\u001b[1;32m    966\u001b[0m     \u001b[39mfor\u001b[39;00m subgroup_name, sub_builder \u001b[39min\u001b[39;00m subgroups\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    967\u001b[0m         \u001b[39m# do not create an empty group without attributes or links\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_group(group, sub_builder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    969\u001b[0m \u001b[39m# write all datasets\u001b[39;00m\n\u001b[1;32m    970\u001b[0m datasets \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mdatasets\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:968\u001b[0m, in \u001b[0;36mHDF5IO.write_group\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[39mif\u001b[39;00m subgroups:\n\u001b[1;32m    966\u001b[0m     \u001b[39mfor\u001b[39;00m subgroup_name, sub_builder \u001b[39min\u001b[39;00m subgroups\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    967\u001b[0m         \u001b[39m# do not create an empty group without attributes or links\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_group(group, sub_builder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    969\u001b[0m \u001b[39m# write all datasets\u001b[39;00m\n\u001b[1;32m    970\u001b[0m datasets \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mdatasets\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:973\u001b[0m, in \u001b[0;36mHDF5IO.write_group\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[39mif\u001b[39;00m datasets:\n\u001b[1;32m    972\u001b[0m     \u001b[39mfor\u001b[39;00m dset_name, sub_builder \u001b[39min\u001b[39;00m datasets\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 973\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_dataset(group, sub_builder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    974\u001b[0m \u001b[39m# write all links\u001b[39;00m\n\u001b[1;32m    975\u001b[0m links \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mlinks\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/utils.py:645\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    644\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:1181\u001b[0m, in \u001b[0;36mHDF5IO.write_dataset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m     \u001b[39m# If the compound data type contains only regular data (i.e., no references) then we can write it as usual\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m         dset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__list_fill__(parent, name, data, options)\n\u001b[1;32m   1182\u001b[0m \u001b[39m# Write a dataset containing references, i.e., a region or object reference.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# NOTE: we can ignore options['io_settings'] for scalar data\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_ref(options[\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:1442\u001b[0m, in \u001b[0;36mHDF5IO.__list_fill__\u001b[0;34m(cls, parent, name, data, options)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     dset[:] \u001b[39m=\u001b[39m data\n\u001b[1;32m   1441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1442\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1443\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/hdmf/backends/hdf5/h5tools.py:1440\u001b[0m, in \u001b[0;36mHDF5IO.__list_fill__\u001b[0;34m(cls, parent, name, data, options)\u001b[0m\n\u001b[1;32m   1438\u001b[0m     dset\u001b[39m.\u001b[39mresize(new_shape)\n\u001b[1;32m   1439\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1440\u001b[0m     dset[:] \u001b[39m=\u001b[39m data\n\u001b[1;32m   1441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1442\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/nwb/lib/python3.8/site-packages/h5py/_hl/dataset.py:1009\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m   1007\u001b[0m mspace \u001b[39m=\u001b[39m h5s\u001b[39m.\u001b[39mcreate_simple(selection\u001b[39m.\u001b[39mexpand_shape(mshape))\n\u001b[1;32m   1008\u001b[0m \u001b[39mfor\u001b[39;00m fspace \u001b[39min\u001b[39;00m selection\u001b[39m.\u001b[39mbroadcast(mshape):\n\u001b[0;32m-> 1009\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49mwrite(mspace, fspace, val, mtype, dxpl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dxpl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:280\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_proxy.pyx:145\u001b[0m, in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_conv.pyx:444\u001b[0m, in \u001b[0;36mh5py._conv.str2vlen\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_conv.pyx:110\u001b[0m, in \u001b[0;36mh5py._conv.generic_converter\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_conv.pyx:249\u001b[0m, in \u001b[0;36mh5py._conv.conv_str2vlen\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't implicitly convert non-string objects to strings"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Writing NWB file\n",
    "'''\n",
    "\n",
    "nwbfile.add_acquisition(image)\n",
    "\n",
    "neuroPAL_module = nwbfile.create_processing_module(\n",
    "    name= 'neuroPAL',\n",
    "    description = 'neuroPAL image data and metadata'\n",
    ")\n",
    "\n",
    "neuroPAL_module.add(vs)\n",
    "neuroPAL_module.add(imaging_vol)\n",
    "neuroPAL_module.add(OpticalChannelRefs)\n",
    "\n",
    "io = NWBHDF5IO(\"Example_NWB.nwb\", mode=\"w\")\n",
    "io.write(nwbfile)\n",
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561-700-75m\n"
     ]
    }
   ],
   "source": [
    "print(channel_1.description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding GCAMP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create time series object for GCAMP time series data\n",
    "TODO: update to be OptPhys GCAMP time series\n",
    "Can also add time series for stimulus data if necessary\n",
    "'''\n",
    "\n",
    "data = load('datapath') #first dimension must be time, second and third dimensions represent X and Y, optional fourth dimension is Z\n",
    "\n",
    "GCAMP_time_series = OnePhotonSeries(\n",
    "    name = \"GCAMP\",\n",
    "    data= data,\n",
    "    rate=1.0,\n",
    "    unit='normalized amplitude'\n",
    ")\n",
    "\n",
    "nwbfile.add_acquisition(GCAMP_time_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "350f9b7359cb9055cd887767acae0b1839a3c0bff8851a59ae54bc63048a16eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
