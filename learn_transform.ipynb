{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os \n","from scipy import io as sio, ndimage\n","\n","import process.file as f\n","import process.atlas as atl\n","import utils.utils as uti\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_data = f.proc_FOCO('data/NP_FOCO_cropped/2022-02-12-w01-NP1')\n","atlas = atl.Atlas()\n","neuron_dict = atlas.create_dictionary()\n","df_atlas = atlas.get_df()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Run on all datasets and calc costs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calc_loss_grad(A, b, data):\n","    loss = 0\n","    dz_tot = 0\n","    A_grad = 0\n","    tot = len(data)\n","    for i, row in data.iterrows():\n","        C = row['rgb data']\n","        mu = row['rgb mu']\n","        sig = row['rgb sigma']\n","        z = A @ C + b - mu\n","        B = np.linalg.inv(sig)\n","        loss += z.T @ B @ z # should be scalar\n","\n","        dz = 2*B@z \n","        dz_tot += dz\n","    \n","        A_grad += dz.reshape(A.shape[0],1) @ C.reshape(C.shape[0],1).T\n","    \n","    b_grad = dz_tot\n","\n","    return loss/tot, A_grad/tot, b_grad/tot\n","\n","def update_params(A, b, A_grad, b_grad, alpha):\n","\n","    newA = A - alpha*A_grad\n","    newb = b - alpha*b_grad\n","\n","    return newA, newb  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def learn_transform(df_data, neuron_dict):\n","    full_data = pd.DataFrame()\n","\n","    for index, row in df_data.iterrows():\n","        if not pd.isnull(row['ID']):\n","            ID = row['ID']\n","            data = np.asarray(row[['R', 'G', 'B']])\n","            mu = neuron_dict[ID]['rgb_mu']\n","            sigma = neuron_dict[ID]['rgb_sigma']\n","            full_data = full_data.append({'ID':ID, 'rgb data':data, 'rgb mu': mu, 'rgb sigma':sigma}, ignore_index=True)\n","\n","    losses = np.zeros(500)\n","\n","    A = np.asarray([[1,0,0],[0, 1, 0],[0, 0, 1]])\n","    b = np.asarray([0,0,0])\n","\n","    alpha = 0.01\n","\n","    for i in range(len(losses)):\n","\n","        loss, A_grad, b_grad = calc_loss_grad(A, b, full_data)\n","        losses[i] = loss\n","\n","        if i%100 ==0:\n","            alpha= alpha/5\n","\n","        A, b = update_params(A, b, A_grad, b_grad, alpha)\n","\n","    return losses, A, b, df_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def transform(data, A, b):\n","    transformed  = pd.DataFrame()\n","\n","    for i, row in data.iterrows():\n","        RGB = np.asarray(row[['R', 'G', 'B']])\n","        newRGB = A @ RGB +b\n","        transformed = transformed.append({'R': newRGB[0], 'G': newRGB[1], 'B':newRGB[2], 'X':row['X'], 'Y':row['Y'], 'Z':row['Z'], 'ID':row['ID'], 'autoID':row['most_likely_ID']}, ignore_index=True)\n","    return transformed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["atlas = atl.Atlas()\n","neuron_dict = atlas.create_dictionary()\n","df_atlas = atlas.get_df()\n","\n","import utils.utils as uti"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","results = pd.DataFrame()\n","trans_dict = {}\n","\n","for folder in os.listdir('data/NP_FOCO_hist'):\n","    if folder == '.DS_Store':\n","        continue\n","    df_data = f.proc_FOCO('data/NP_FOCO_hist/'+folder)\n","    losses, A, b, df_data = learn_transform(df_data, neuron_dict)\n","\n","    trans_data = transform(df_data, A, b)\n","    trans_dict[folder] = trans_data\n","    \n","    base_xyz, base_rgb = uti.calc_costs(df_atlas, atlas.sigma, df_data)\n","    trans_xyz, trans_rgb = uti.calc_costs(df_atlas, atlas.sigma, trans_data)\n","\n","    results = results.append({'folder':folder, 'base_xyz': base_xyz, 'base_rgb':base_rgb, 'trans_xyz':trans_xyz, 'trans_rgb':trans_rgb, 'A':A, 'b':b}, ignore_index=True)\n","\n","    \n","     \n","    plt.plot(losses)\n","    plt.show()\n","    plt.cla()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib qt\n","\n","labels = results['folder']\n","x = np.arange(len(labels))\n","width = 0.6\n","\n","fig, ax = plt.subplots()\n","\n","rects1 = ax.bar(x-width/4, np.asarray(results['base_rgb']), width = width/2, label = 'Base RGB alignment cost')\n","rects2 = ax.bar(x+width/4, np.asarray(results['trans_rgb']), width = width/2, label = 'Transformed RGB alignment cost')\n","\n","ax.set_ylabel('Mahalanobis distance')\n","ax.set_title('Effect of learned color transformations on alignment cost')\n","\n","ax.set_xticks(x)\n","ax.set_xticklabels(labels)\n","ax.tick_params(labelrotation=30)\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","import visualize.visualizer as vis\n","\n","vis.plot_RGB_super(atlas.df, atlas.sigma, trans_dict['2022-02-12-w01-NP1'])\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_cropped/2022-02-12-w01-NP1/'))\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_hist/2022-02-12-w01-NP1/'))\n","vis.plot_RGB_super(atlas.df, atlas.sigma, trans_dict['2022-04-26-w01-NP1'])\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_cropped/2022-04-26-w01-NP1/'))\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_hist/2022-04-26-w01-NP1/'))\n","vis.plot_RGB_super(atlas.df, atlas.sigma, trans_dict['2021-12-03-w00-NP1'])\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_cropped/2021-12-03-w00-NP1/'))\n","vis.plot_RGB_super(atlas.df, atlas.sigma, f.proc_FOCO('data/NP_FOCO_hist/2021-12-03-w00-NP1/'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results.loc[5]['A']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Transform on Z-scored data after applying median blur (incomplete)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","results = pd.DataFrame()\n","trans_dict = {}\n","\n","for folder in os.listdir('data/NP_FOCO_transform'):\n","    if folder == '.DS_Store':\n","        continue\n","\n","    df_data = f.proc_FOCO('data/NP_FOCO_transform/'+folder)\n","\n","    \n","    losses, A, b, df_data = learn_transform(df_data)\n","\n","    trans_data = transform(df_data, A, b)\n","    trans_dict[folder] = trans_data\n","    \n","    base_xyz, base_rgb = uti.calc_costs(df_atlas, atlas.sigma, df_data)\n","    trans_xyz, trans_rgb = uti.calc_costs(df_atlas, atlas.sigma, trans_data)\n","\n","    results = results.append({'folder':folder, 'base_xyz': base_xyz, 'base_rgb':base_rgb, 'trans_xyz':trans_xyz, 'trans_rgb':trans_rgb, 'A':A, 'b':b}, ignore_index=True) \n","    plt.plot(losses)\n","    plt.show()\n","    plt.cla()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_df(folder):\n","\n","    for f in os.listdir(folder):\n","        if f[-4:] == '.mat':\n","            imfile = sio.loadmat(folder +'/'+f)\n","        elif f == 'blobs.csv':\n","            gt_file = pd.read_csv(f)\n","\n","    data = imfile['data']\n","    channels = imfile['prefs']['RGBW'][0][0]-1\n","    RGBW = np.squeeze(data[:,:,:, channels])\n","\n","    blur_im = ndimage.median_filter(RGBW, size=(5, 5, 3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Transform on raw data\n","\n","Requires dataframe with raw RGB values for each neuron and atlas with average/stdev of raw pixel values for each neuron in neuroPAL datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calc_loss_grad(A, b, data):\n","    loss = 0\n","    dz_tot = 0\n","    A_grad = np.zeros((A.shape))\n","    tot = len(data)\n","    for i, row in data.iterrows():\n","        C = row['rgb data']\n","        mu = row['rgb mu']\n","        sig = row['rgb sigma']\n","        z = A @ C + b - mu\n","        B = np.linalg.inv(sig)\n","        loss += z.T @ B @ z # should be scalar\n","\n","        dz = 2*B@z \n","        dz_tot += dz\n","\n","        A_grad_curr = dz.reshape(A.shape[0],1) @ C.reshape(C.shape[0],1).T\n","\n","        grad = np.diagonal(A_grad_curr)\n","        A_grad[0,0] +=  grad[0]\n","        A_grad[1,1] += grad[1]\n","        A_grad[2,2] += grad[2]\n","        A_grad[3,3] += grad[3]\n","    \n","    b_grad = dz_tot\n","\n","    return loss/tot, A_grad/tot, b_grad/tot\n","\n","def update_params(A, b, A_grad, b_grad, alpha):\n","\n","    newA = A - alpha*A_grad\n","    newb = b - alpha*b_grad\n","\n","    return newA, newb    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def learn_transform(df_data, neuron_dict, alpha = 0.000000001):\n","    full_data = pd.DataFrame()\n","\n","    for index, row in df_data.iterrows():\n","        if not pd.isnull(row['ID']):\n","            ID = row['ID']\n","            data = np.asarray(row[['R', 'G', 'B', 'W']])\n","            mu = neuron_dict[ID]['rgbw_mu']\n","            sigma = neuron_dict[ID]['rgbw_sigma']\n","            full_data = full_data.append({'ID':ID, 'rgb data':data, 'rgb mu': mu, 'rgb sigma':sigma}, ignore_index=True)\n","\n","    losses = np.zeros(600)\n","\n","    A = np.asarray([[1,0,0, 0],[0, 1, 0, 0],[0, 0, 1, 0], [0,0,0,1]])\n","    b = np.asarray([0,0,0, 0])\n","\n","    alpha = alpha\n","\n","    for i in range(len(losses)):\n","\n","        loss, A_grad, b_grad = calc_loss_grad(A, b, full_data)\n","        losses[i] = loss\n","\n","        if i%200 ==0:\n","            alpha= alpha/5\n","\n","        A, b = update_params(A, b, A_grad, b_grad, alpha)\n","\n","    return losses, A, b, df_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def transform(data, A, b):\n","    transformed  = pd.DataFrame()\n","\n","    for i, row in data.iterrows():\n","        RGBW = np.asarray(row[['R', 'G', 'B', 'W']])\n","        newRGBW = A @ RGBW +b\n","        transformed = transformed.append({'R': newRGBW[0], 'G': newRGBW[1], 'B':newRGBW[2], 'W':newRGBW[3], 'X':row['X'], 'Y':row['Y'], 'Z':row['Z'], 'ID':row['ID']}, ignore_index=True)\n","    return transformed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_raw_atlas(file = 'data/atlases/raw_atlas.mat'):\n","\n","    neur_dict = {}\n","    mat_dict = sio.loadmat(file)\n","    \n","    labels = np.asarray([mat_dict['labels'][i][0][0] for i in range(1, len(mat_dict['labels']))])\n","    mus = mat_dict['avgs'][1:]\n","    sigmas = mat_dict['covars'][1:,:,:]\n","\n","    for i, label in enumerate(labels):\n","        xyz_mu = mus[i, 0:3]\n","        xyz_sigma = sigmas[i, 0:3, 0:3]\n","        rgbw_mu = mus[i, 3:]\n","        rgbw_sigma = sigmas[i, 3:, 3:]\n","        vars = (np.diagonal(rgbw_sigma)+0.01)\n","        covar_mat = np.zeros((4,4))\n","        covar_mat[0,0] =  vars[0]\n","        covar_mat[1,1] = vars[1]\n","        covar_mat[2,2] = vars[2]\n","        covar_mat[3,3] = vars[3]\n","        \n","        neur_dict[label] = {'xyz_mu':xyz_mu, 'xyz_sigma': xyz_sigma, 'rgbw_mu': rgbw_mu, 'rgbw_sigma':covar_mat}\n","\n","    return neur_dict           "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_raw_data(folder):\n","\n","    for file in os.listdir(folder):\n","        \n","        if file == 'hist_equal_image.mat':\n","            datfile = sio.loadmat(folder+'/'+file)\n","        elif file[-4:] == '.mat' and file[-6:-4]!= 'ID':\n","            imfile = sio.loadmat(folder+'/'+file)\n","        elif file == 'blobs.csv':\n","            gtfile = pd.read_csv(folder+'/'+file)\n","\n","    #data= imfile['data']\n","    #channels = [0,2,4,1]\n","    #RGBW = np.squeeze(data[:,:,:, channels])\n","    RGBW = datfile['Hist_RGBW']\n","\n","\n","    Xscale = imfile['info']['scale'][0][0][0][0]\n","    Yscale = imfile['info']['scale'][0][0][1][0]\n","    Zscale = imfile['info']['scale'][0][0][2][0]\n","\n","    df_data = pd.DataFrame()\n","\n","    for i, row in gtfile.iterrows():\n","        XYZ  = np.asarray(row[['X', 'Y', 'Z']])\n","        color = np.transpose(np.squeeze(RGBW[XYZ[1], XYZ[0], XYZ[2], :]))\n","\n","        df_data = df_data.append({'ID': row['ID'], 'X':XYZ[0], 'Y':XYZ[1], 'Z':XYZ[2], 'R': color[0], 'G':color[1], 'B':color[2], 'W':color[3]}, ignore_index = True)\n","\n","    df_data.loc[df_data['ID'].str[-1].isin(['?']),'ID'] = np.nan\n","    \n","    return df_data, RGBW\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["atlas = atl.Atlas()\n","neuron_dict = atlas.create_dictionary()\n","df_atlas = atlas.get_df()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["neur_dict['ADAR']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","results = pd.DataFrame()\n","trans_dict = {}\n","\n","folder = 'data/NP_FOCO_hist/2022-02-12-w01-NP1'\n","\n","df_data, RGBW = get_raw_data('data/NP_FOCO_hist/2022-02-12-w01-NP1')\n","\n","neur_dict = get_raw_atlas()\n","\n","losses, A, b, df_data = learn_transform(df_data, neur_dict)\n","\n","trans_data = transform(df_data, A, b)\n","trans_dict[folder] = trans_data\n","\n","base_xyz, base_rgb = uti.calc_costs(df_atlas, atlas.sigma, df_data)\n","trans_xyz, trans_rgb = uti.calc_costs(df_atlas, atlas.sigma, trans_data)\n","\n","trans_RGBW = RGBW @ A +b\n","\n","trans_RGBW = trans_RGBW.astype('float64')\n","\n","sio.savemat('data/NP_FOCO_trans/2022-02-12-w01-NP1/'+'trans_image.mat', {'trans_im':trans_RGBW})\n","\n","results = results.append({'folder':folder, 'base_xyz': base_xyz, 'base_rgb':base_rgb, 'trans_xyz':trans_xyz, 'trans_rgb':trans_rgb, 'A':A, 'b':b}, ignore_index=True) \n","plt.plot(losses)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","results = pd.DataFrame()\n","trans_dict = {}\n","\n","neur_dict = get_raw_atlas()\n","\n","for folder in os.listdir('data/NP_FOCO_hist'):\n","    if folder == '.DS_Store':\n","        continue\n","\n","    print(folder)\n","\n","    df_data, RGBW = get_raw_data('data/NP_FOCO_hist/'+folder)\n","\n","    losses, A, b, df_data = learn_transform(df_data, neur_dict)\n","\n","    trans_data = transform(df_data, A, b)\n","    trans_dict[folder] = trans_data\n","    \n","    base_xyz, base_rgb = uti.calc_costs(df_atlas, atlas.sigma, df_data)\n","    trans_xyz, trans_rgb = uti.calc_costs(df_atlas, atlas.sigma, trans_data)\n","\n","    results = results.append({'folder':folder, 'base_xyz': base_xyz, 'base_rgb':base_rgb, 'trans_xyz':trans_xyz, 'trans_rgb':trans_rgb, 'A':A, 'b':b}, ignore_index=True)\n","\n","\n","    for i in range(4):\n","        trans_RGBW[:,:,:,i] = RGBW[:,:,:,i] * A[i,i] + b[i]\n","        print(np.mean(trans_RGBW[:,:,:,i]))\n","        print(np.mean(RGBW[:,:,:,i]))\n","\n","    trans_RGBW = trans_RGBW.astype('float64')\n","\n","    sio.savemat('data/NP_FOCO_trans/'+folder+'/'+'trans_image.mat', {'trans_im':trans_RGBW})\n","\n","    plt.plot(losses)\n","    plt.show()\n","    plt.cla()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_RGB_comp(df_data, trans_data, atlas_data):\n","\n","    fig, axs = plt.subplots(3,3)\n","\n","    axs[0,0].scatter(df_data[['R']],df_data[['G']])\n","    axs[0,1].scatter(df_data[['G']], df_data[['B']])\n","    axs[0,2].scatter(df_data[['R']], df_data[['B']])\n","    axs[1,0].scatter(trans_data[['R']],trans_data[['G']])\n","    axs[1,1].scatter(trans_data[['G']],trans_data[['B']])\n","    axs[1,2].scatter(trans_data[['R']],trans_data[['B']])\n","    axs[2,0].scatter(atlas_data[['R']],atlas_data[['G']])\n","    axs[2,1].scatter(atlas_data[['G']],atlas_data[['B']])\n","    axs[2,2].scatter(atlas_data[['R']],atlas_data[['B']])\n","\n","    plt.show()\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Transform Z scored data post histogram equalization and pre alignment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_zscore_data(folder):\n","\n","    for file in os.listdir(folder):\n","        \n","        if file == 'hist_equal_image.mat':\n","            datfile = sio.loadmat(folder+'/'+file)\n","        elif file[-4:] == '.mat' and file[-6:-4]!= 'ID':\n","            imfile = sio.loadmat(folder+'/'+file)\n","        elif file == 'blobs.csv':\n","            gtfile = pd.read_csv(folder+'/'+file)\n","\n","    #data= imfile['data']\n","    #channels = [0,2,4,1]\n","    #RGBW = np.squeeze(data[:,:,:, channels])\n","    RGBW = datfile['Hist_RGBW']\n","    Zscored = RGBW\n","\n","    for i in range(RGBW.shape[3]):\n","        Zscored[:,:,:,i] = (RGBW[:,:,:,i]- np.mean(RGBW[:,:,:,i]))/np.std(RGBW[:,:,:,i])\n","\n","\n","    Xscale = imfile['info']['scale'][0][0][0][0]\n","    Yscale = imfile['info']['scale'][0][0][1][0]\n","    Zscale = imfile['info']['scale'][0][0][2][0]\n","\n","    df_data = pd.DataFrame()\n","\n","    for i, row in gtfile.iterrows():\n","        XYZ  = np.asarray(row[['X', 'Y', 'Z']])\n","        color = np.transpose(np.squeeze(Zscored[XYZ[1], XYZ[0], XYZ[2], :]))\n","\n","        df_data = df_data.append({'ID': row['ID'], 'X':XYZ[0], 'Y':XYZ[1], 'Z':XYZ[2], 'R': color[0], 'G':color[1], 'B':color[2], 'W':color[3]}, ignore_index = True)\n","\n","    df_data.loc[df_data['ID'].str[-1].isin(['?']),'ID'] = np.nan\n","    \n","    return df_data, Zscored\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calc_loss_grad(A, b, data):\n","    loss = 0\n","    dz_tot = 0\n","    A_grad = 0\n","    tot = len(data)\n","    for i, row in data.iterrows():\n","        C = row['rgb data']\n","        mu = row['rgb mu']\n","        sig = row['rgb sigma']\n","        z = A @ C + b - mu\n","        B = np.linalg.inv(sig)\n","        loss += z.T @ B @ z # should be scalar\n","\n","        dz = 2*B@z \n","        dz_tot += dz\n","\n","        A_grad_curr = dz.reshape(A.shape[0],1) @ C.reshape(C.shape[0],1).T\n","\n","        A_grad += A_grad_curr\n","    \n","    b_grad = dz_tot\n","\n","    return loss/tot, A_grad/tot, b_grad/tot\n","\n","def update_params(A, b, A_grad, b_grad, alpha):\n","\n","    newA = A - alpha*A_grad\n","    newb = b - alpha*b_grad\n","\n","    return newA, newb    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def learn_transform(df_data, neuron_dict, alpha = 0.000000001):\n","    full_data = pd.DataFrame()\n","\n","    for index, row in df_data.iterrows():\n","        if not pd.isnull(row['ID']):\n","            ID = row['ID']\n","            data = np.asarray(row[['R', 'G', 'B']])\n","            mu = neuron_dict[ID]['rgb_mu']\n","            sigma = neuron_dict[ID]['rgb_sigma']\n","            full_data = full_data.append({'ID':ID, 'rgb data':data, 'rgb mu': mu, 'rgb sigma':sigma}, ignore_index=True)\n","\n","    losses = np.zeros(2000)\n","\n","    A = np.asarray([[1,0,0],[0, 1, 0],[0, 0, 1]])\n","    b = np.asarray([0,0,0])\n","\n","    alpha = alpha\n","\n","    for i in range(len(losses)):\n","\n","        loss, A_grad, b_grad = calc_loss_grad(A, b, full_data)\n","        losses[i] = loss\n","\n","        if i%500 ==0:\n","            alpha= alpha/2\n","\n","        A, b = update_params(A, b, A_grad, b_grad, alpha)\n","\n","    return losses, A, b, df_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def transform(data, A, b):\n","    transformed  = pd.DataFrame()\n","\n","    for i, row in data.iterrows():\n","        RGB = np.asarray(row[['R', 'G', 'B']])\n","        newRGB = A @ RGB +b\n","        transformed = transformed.append({'R': newRGB[0], 'G': newRGB[1], 'B':newRGB[2], 'X':row['X'], 'Y':row['Y'], 'Z':row['Z'], 'ID':row['ID']}, ignore_index=True)\n","    return transformed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["atlas = atl.Atlas()\n","neuron_dict = atlas.create_dictionary()\n","df_atlas = atlas.get_df()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","results = pd.DataFrame()\n","trans_dict = {}\n","\n","neur_dict = atlas.create_dictionary()\n","\n","for folder in os.listdir('data/NP_FOCO_hist'):\n","    if folder == '.DS_Store':\n","        continue\n","\n","    print(folder)\n","\n","    df_data, RGBW = get_zscore_data('data/NP_FOCO_hist/'+folder)\n","\n","    losses, A, b, df_data = learn_transform(df_data, neur_dict, alpha = 0.001)\n","\n","    trans_data = transform(df_data, A, b)\n","    trans_dict[folder] = trans_data\n","    \n","    base_xyz, base_rgb = uti.calc_costs(df_atlas, atlas.sigma, df_data)\n","    trans_xyz, trans_rgb = uti.calc_costs(df_atlas, atlas.sigma, trans_data)\n","\n","    results = results.append({'folder':folder, 'base_xyz': base_xyz, 'base_rgb':base_rgb, 'trans_xyz':trans_xyz, 'trans_rgb':trans_rgb, 'A':A, 'b':b}, ignore_index=True)\n","\n","    trans_data.to_csv('data/NP_FOCO_trans/'+folder+'/trans_data.csv',index=False)\n","    \n","    #sio.savemat('data/NP_FOCO_trans/'+folder+'/'+'trans_data.mat', {'trans_data':trans_data})\n","\n","    plt.plot(losses)\n","    plt.show()\n","    plt.cla()"]}],"metadata":{"kernelspec":{"display_name":"alignment","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9a246cbeb7e7d64baab736c5e4f8a8cf6205ec6202ebfe668ed4dad2c6630795"}}},"nbformat":4,"nbformat_minor":2}
